{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fsdl_hw2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFiQhrTCOLJz",
        "outputId": "5060e8b1-07ec-40ce-bf31-4a9f73ec8ebc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 27 02:02:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUExfnqpOdV9",
        "outputId": "8f2f7c3a-5c16-4276-c690-137ae4d9e4bf"
      },
      "source": [
        "# FSDL Spring 2021 Setup\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\n",
        "%cd fsdl-text-recognizer-2021-labs\n",
        "!pip install pytorch_lightning==1.1.4\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 216 (delta 81), reused 175 (delta 49), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (216/216), 2.88 MiB | 6.96 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "/content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs\n",
            "Requirement already satisfied: pytorch_lightning==1.1.4 in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.7.1+cu101)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (0.18.2)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (0.8.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (53.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.36.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.27.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->pytorch_lightning==1.1.4) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.7.0)\n",
            "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.7.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (5.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (20.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcH3fp-kOrva",
        "outputId": "f7758c2c-f25a-456b-ba41-3847929b7139"
      },
      "source": [
        "cd lab2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/lab2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWVFIKkcOt-2",
        "outputId": "08886b69-92fc-4f1c-aca9-27d924392550"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=MNIST --max_epochs=5 --gpus=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:00, 10065776.01it/s]                \n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 128622.76it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 2383820.41it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 44578.75it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "2021-02-27 02:25:13.709505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.6 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 1.3 K \n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 M     Total params\n",
            "Epoch 0:  91% 430/470 [00:16<00:01, 25.45it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  92% 433/470 [00:16<00:01, 25.54it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  93% 438/470 [00:17<00:01, 25.62it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Validating:  20% 8/40 [00:00<00:00, 35.02it/s]\u001b[A\n",
            "Epoch 0:  94% 443/470 [00:17<00:01, 25.70it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  95% 448/470 [00:17<00:00, 25.78it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  96% 453/470 [00:17<00:00, 25.85it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0:  97% 458/470 [00:17<00:00, 25.92it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Validating:  70% 28/40 [00:00<00:00, 35.04it/s]\u001b[A\n",
            "Epoch 0:  99% 463/470 [00:17<00:00, 26.00it/s, loss=0.0602, v_num=0, val_loss=2.3, val_acc=0.133]\n",
            "Epoch 0: 100% 470/470 [00:18<00:00, 25.95it/s, loss=0.0602, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  91% 430/470 [00:16<00:01, 25.55it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  93% 435/470 [00:16<00:01, 25.67it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  94% 440/470 [00:17<00:01, 25.75it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  95% 445/470 [00:17<00:00, 25.82it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  96% 450/470 [00:17<00:00, 25.90it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Validating:  50% 20/40 [00:00<00:00, 35.08it/s]\u001b[A\n",
            "Epoch 1:  97% 455/470 [00:17<00:00, 25.98it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  98% 460/470 [00:17<00:00, 26.05it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1:  99% 465/470 [00:17<00:00, 26.11it/s, loss=0.0287, v_num=0, val_loss=0.0653, val_acc=0.983]\n",
            "Epoch 1: 100% 470/470 [00:18<00:00, 26.08it/s, loss=0.0287, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  91% 430/470 [00:16<00:01, 25.55it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  93% 435/470 [00:16<00:01, 25.66it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  94% 440/470 [00:17<00:01, 25.74it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  95% 445/470 [00:17<00:00, 25.82it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  96% 450/470 [00:17<00:00, 25.90it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Validating:  50% 20/40 [00:00<00:00, 35.32it/s]\u001b[A\n",
            "Epoch 2:  97% 455/470 [00:17<00:00, 25.98it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  98% 460/470 [00:17<00:00, 26.04it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2:  99% 465/470 [00:17<00:00, 26.11it/s, loss=0.0224, v_num=0, val_loss=0.0509, val_acc=0.986]\n",
            "Epoch 2: 100% 470/470 [00:18<00:00, 26.06it/s, loss=0.0224, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  91% 430/470 [00:16<00:01, 25.35it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  93% 435/470 [00:17<00:01, 25.45it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  94% 440/470 [00:17<00:01, 25.54it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  95% 445/470 [00:17<00:00, 25.61it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  96% 450/470 [00:17<00:00, 25.69it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Validating:  50% 20/40 [00:00<00:00, 34.15it/s]\u001b[A\n",
            "Epoch 3:  97% 455/470 [00:17<00:00, 25.76it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  98% 460/470 [00:17<00:00, 25.84it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3:  99% 465/470 [00:17<00:00, 25.92it/s, loss=0.021, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 3: 100% 470/470 [00:18<00:00, 25.89it/s, loss=0.021, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  91% 430/470 [00:16<00:01, 25.51it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  93% 435/470 [00:16<00:01, 25.63it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  94% 440/470 [00:17<00:01, 25.70it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  95% 445/470 [00:17<00:00, 25.77it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  96% 450/470 [00:17<00:00, 25.85it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Validating:  50% 20/40 [00:00<00:00, 34.81it/s]\u001b[A\n",
            "Epoch 4:  97% 455/470 [00:17<00:00, 25.92it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  98% 460/470 [00:17<00:00, 26.00it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4:  99% 465/470 [00:17<00:00, 26.08it/s, loss=0.0124, v_num=0, val_loss=0.0379, val_acc=0.989]\n",
            "Epoch 4: 100% 470/470 [00:17<00:00, 26.15it/s, loss=0.0124, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Epoch 4: 100% 470/470 [00:18<00:00, 26.10it/s, loss=0.0124, v_num=0, val_loss=0.0441, val_acc=0.987]\n",
            "Testing: 100% 79/79 [00:02<00:00, 36.29it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9879, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbNFCFZCTaJI",
        "outputId": "2e3ea936-0e3e-4f32-8895-7bc89a8e0b7b"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/matlab.zip to /content/fsdl-text-recognizer-2021-labs/fsdl-text-recognizer-2021-labs/lab2/fsdl-text-recognizer-2021-labs/data/downloaded/emnist/matlab.zip...\n",
            "709MB [00:09, 81.5MB/s]               \n",
            "Computing SHA-256...\n",
            "Unzipping EMNIST...\n",
            "Loading training data from .mat file\n",
            "Balancing classes to reduce amount of data\n",
            "Saving to HDF5 in a compressed format...\n",
            "Saving essential dataset parameters to text_recognizer/datasets...\n",
            "Cleaning up...\n",
            "2021-02-27 02:27:38.240850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:30<00:07, 65.77it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195] \n",
            "Epoch 0:  80% 2035/2542 [00:30<00:07, 65.82it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2049/2542 [00:31<00:07, 66.04it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2063/2542 [00:31<00:07, 66.28it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2077/2542 [00:31<00:06, 66.51it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2091/2542 [00:31<00:06, 66.74it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2105/2542 [00:31<00:06, 66.97it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2119/2542 [00:31<00:06, 67.19it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2133/2542 [00:31<00:06, 67.42it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2147/2542 [00:31<00:05, 67.64it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2161/2542 [00:31<00:05, 67.86it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2175/2542 [00:31<00:05, 68.09it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2189/2542 [00:32<00:05, 68.30it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2203/2542 [00:32<00:04, 68.51it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2217/2542 [00:32<00:04, 68.72it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2231/2542 [00:32<00:04, 68.92it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2245/2542 [00:32<00:04, 69.14it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2259/2542 [00:32<00:04, 69.36it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2273/2542 [00:32<00:03, 69.57it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2287/2542 [00:32<00:03, 69.78it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2301/2542 [00:32<00:03, 69.99it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2315/2542 [00:32<00:03, 70.20it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2329/2542 [00:33<00:03, 70.40it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2343/2542 [00:33<00:02, 70.61it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2357/2542 [00:33<00:02, 70.81it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2371/2542 [00:33<00:02, 71.01it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2386/2542 [00:33<00:02, 71.24it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2401/2542 [00:33<00:01, 71.45it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2416/2542 [00:33<00:01, 71.66it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2431/2542 [00:33<00:01, 71.87it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2446/2542 [00:33<00:01, 72.08it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2461/2542 [00:34<00:01, 72.29it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2476/2542 [00:34<00:00, 72.49it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2491/2542 [00:34<00:00, 72.70it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2506/2542 [00:34<00:00, 72.90it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2521/2542 [00:34<00:00, 73.10it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2536/2542 [00:34<00:00, 73.31it/s, loss=0.57, v_num=1, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:34<00:00, 73.17it/s, loss=0.57, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:31<00:07, 64.99it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2040/2542 [00:31<00:07, 65.12it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2055/2542 [00:31<00:07, 65.36it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2070/2542 [00:31<00:07, 65.60it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2085/2542 [00:31<00:06, 65.84it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  83% 2100/2542 [00:31<00:06, 66.08it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  83% 2115/2542 [00:31<00:06, 66.32it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2130/2542 [00:32<00:06, 66.56it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  19% 97/509 [00:00<00:03, 134.00it/s]\u001b[A\n",
            "Epoch 1:  84% 2145/2542 [00:32<00:05, 66.79it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2160/2542 [00:32<00:05, 67.02it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2175/2542 [00:32<00:05, 67.26it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2190/2542 [00:32<00:05, 67.49it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2205/2542 [00:32<00:04, 67.71it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2220/2542 [00:32<00:04, 67.94it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2235/2542 [00:32<00:04, 68.16it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2250/2542 [00:32<00:04, 68.38it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2265/2542 [00:33<00:04, 68.61it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2280/2542 [00:33<00:03, 68.83it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2295/2542 [00:33<00:03, 69.04it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2310/2542 [00:33<00:03, 69.25it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2325/2542 [00:33<00:03, 69.47it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2340/2542 [00:33<00:02, 69.67it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  60% 307/509 [00:02<00:01, 128.95it/s]\u001b[A\n",
            "Epoch 1:  93% 2355/2542 [00:33<00:02, 69.85it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2370/2542 [00:33<00:02, 70.04it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2385/2542 [00:33<00:02, 70.25it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2400/2542 [00:34<00:02, 70.46it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  95% 2415/2542 [00:34<00:01, 70.66it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2430/2542 [00:34<00:01, 70.87it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2445/2542 [00:34<00:01, 71.08it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  97% 2460/2542 [00:34<00:01, 71.28it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  97% 2475/2542 [00:34<00:00, 71.48it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2490/2542 [00:34<00:00, 71.68it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2505/2542 [00:34<00:00, 71.89it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2520/2542 [00:34<00:00, 72.07it/s, loss=0.508, v_num=1, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  96% 487/509 [00:03<00:00, 131.97it/s]\u001b[A\n",
            "Epoch 1: 100% 2542/2542 [00:35<00:00, 72.20it/s, loss=0.508, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:31<00:07, 64.54it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2040/2542 [00:31<00:07, 64.66it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2055/2542 [00:31<00:07, 64.90it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2070/2542 [00:31<00:07, 65.15it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2085/2542 [00:31<00:06, 65.38it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2100/2542 [00:32<00:06, 65.62it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2115/2542 [00:32<00:06, 65.86it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  16% 82/509 [00:00<00:03, 132.37it/s]\u001b[A\n",
            "Epoch 2:  84% 2130/2542 [00:32<00:06, 66.09it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2145/2542 [00:32<00:05, 66.32it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2160/2542 [00:32<00:05, 66.54it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2175/2542 [00:32<00:05, 66.78it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2190/2542 [00:32<00:05, 67.00it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2205/2542 [00:32<00:05, 67.22it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2220/2542 [00:32<00:04, 67.45it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2235/2542 [00:33<00:04, 67.67it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2250/2542 [00:33<00:04, 67.89it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2265/2542 [00:33<00:04, 68.11it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2280/2542 [00:33<00:03, 68.33it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2295/2542 [00:33<00:03, 68.55it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  51% 262/509 [00:01<00:01, 131.38it/s]\u001b[A\n",
            "Epoch 2:  91% 2310/2542 [00:33<00:03, 68.76it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2325/2542 [00:33<00:03, 68.97it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2340/2542 [00:33<00:02, 69.17it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2355/2542 [00:33<00:02, 69.38it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2370/2542 [00:34<00:02, 69.59it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2385/2542 [00:34<00:02, 69.80it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2400/2542 [00:34<00:02, 70.00it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2415/2542 [00:34<00:01, 70.21it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2430/2542 [00:34<00:01, 70.41it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2445/2542 [00:34<00:01, 70.61it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2460/2542 [00:34<00:01, 70.81it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2475/2542 [00:34<00:00, 71.01it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2490/2542 [00:34<00:00, 71.21it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2505/2542 [00:35<00:00, 71.39it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  93% 472/509 [00:03<00:00, 128.99it/s]\u001b[A\n",
            "Epoch 2:  99% 2520/2542 [00:35<00:00, 71.59it/s, loss=0.463, v_num=1, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:35<00:00, 71.71it/s, loss=0.463, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2033/2542 [00:31<00:07, 64.51it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2040/2542 [00:31<00:07, 64.63it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  81% 2055/2542 [00:31<00:07, 64.88it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  81% 2070/2542 [00:31<00:07, 65.12it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2085/2542 [00:31<00:06, 65.36it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2100/2542 [00:32<00:06, 65.60it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2115/2542 [00:32<00:06, 65.85it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2130/2542 [00:32<00:06, 66.09it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  19% 98/509 [00:00<00:03, 134.69it/s]\u001b[A\n",
            "Epoch 3:  84% 2145/2542 [00:32<00:05, 66.30it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2160/2542 [00:32<00:05, 66.53it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2175/2542 [00:32<00:05, 66.76it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2190/2542 [00:32<00:05, 66.97it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2205/2542 [00:32<00:05, 67.20it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2220/2542 [00:32<00:04, 67.42it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2235/2542 [00:33<00:04, 67.65it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2250/2542 [00:33<00:04, 67.88it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2265/2542 [00:33<00:04, 68.10it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2280/2542 [00:33<00:03, 68.32it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2295/2542 [00:33<00:03, 68.54it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  51% 262/509 [00:01<00:01, 134.04it/s]\u001b[A\n",
            "Epoch 3:  91% 2310/2542 [00:33<00:03, 68.75it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2325/2542 [00:33<00:03, 68.97it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2340/2542 [00:33<00:02, 69.18it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2355/2542 [00:33<00:02, 69.39it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2370/2542 [00:34<00:02, 69.60it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2385/2542 [00:34<00:02, 69.82it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2400/2542 [00:34<00:02, 70.02it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  95% 2415/2542 [00:34<00:01, 70.23it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2430/2542 [00:34<00:01, 70.42it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2445/2542 [00:34<00:01, 70.63it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2460/2542 [00:34<00:01, 70.83it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2475/2542 [00:34<00:00, 71.03it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2490/2542 [00:34<00:00, 71.23it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2505/2542 [00:35<00:00, 71.43it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  93% 472/509 [00:03<00:00, 133.00it/s]\u001b[A\n",
            "Epoch 3:  99% 2520/2542 [00:35<00:00, 71.63it/s, loss=0.437, v_num=1, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:35<00:00, 71.76it/s, loss=0.437, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2033/2542 [00:31<00:07, 64.50it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2040/2542 [00:31<00:07, 64.62it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2055/2542 [00:31<00:07, 64.87it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2070/2542 [00:31<00:07, 65.11it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2085/2542 [00:31<00:06, 65.35it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2100/2542 [00:32<00:06, 65.59it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2115/2542 [00:32<00:06, 65.83it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2130/2542 [00:32<00:06, 66.07it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  19% 97/509 [00:00<00:03, 133.48it/s]\u001b[A\n",
            "Epoch 4:  84% 2145/2542 [00:32<00:05, 66.31it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  85% 2160/2542 [00:32<00:05, 66.53it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2175/2542 [00:32<00:05, 66.77it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2190/2542 [00:32<00:05, 66.99it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2205/2542 [00:32<00:05, 67.22it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2220/2542 [00:32<00:04, 67.44it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2235/2542 [00:33<00:04, 67.66it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2250/2542 [00:33<00:04, 67.89it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2265/2542 [00:33<00:04, 68.10it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2280/2542 [00:33<00:03, 68.32it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2295/2542 [00:33<00:03, 68.53it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2310/2542 [00:33<00:03, 68.74it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2325/2542 [00:33<00:03, 68.96it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  57% 292/509 [00:02<00:01, 131.56it/s]\u001b[A\n",
            "Epoch 4:  92% 2340/2542 [00:33<00:02, 69.17it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2355/2542 [00:33<00:02, 69.38it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2370/2542 [00:34<00:02, 69.59it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2385/2542 [00:34<00:02, 69.80it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2400/2542 [00:34<00:02, 70.00it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  95% 2415/2542 [00:34<00:01, 70.20it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2430/2542 [00:34<00:01, 70.39it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2445/2542 [00:34<00:01, 70.60it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2460/2542 [00:34<00:01, 70.80it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2475/2542 [00:34<00:00, 71.00it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2490/2542 [00:34<00:00, 71.21it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2505/2542 [00:35<00:00, 71.41it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2520/2542 [00:35<00:00, 71.60it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2535/2542 [00:35<00:00, 71.80it/s, loss=0.408, v_num=1, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:35<00:00, 71.87it/s, loss=0.408, v_num=1, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:35<00:00, 71.53it/s, loss=0.408, v_num=1, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:03<00:00, 137.26it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8061, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ac9-sHFTedF",
        "outputId": "44f68065-1b2a-4ccc-dfda-90bf139c62d5"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=50 --gpus=1 --overfit_batches=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-27 02:30:47.187626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  50% 2/4 [00:00<00:00, 44.37it/s, loss=4.4, v_num=2, val_loss=4.42, val_acc=0.00391] \n",
            "Epoch 0: 100% 4/4 [00:00<00:00, 24.65it/s, loss=4.4, v_num=2, val_loss=4.21, val_acc=0.0703] \n",
            "Epoch 1:  50% 2/4 [00:00<00:00, 47.13it/s, loss=4.28, v_num=2, val_loss=4.21, val_acc=0.0703]\n",
            "Epoch 1: 100% 4/4 [00:00<00:00, 27.85it/s, loss=4.28, v_num=2, val_loss=3.91, val_acc=0.0469]\n",
            "Epoch 2:  50% 2/4 [00:00<00:00, 46.53it/s, loss=4.13, v_num=2, val_loss=3.91, val_acc=0.0469]\n",
            "Epoch 2: 100% 4/4 [00:00<00:00, 29.72it/s, loss=4.13, v_num=2, val_loss=3.5, val_acc=0.281]  \n",
            "Epoch 3:  50% 2/4 [00:00<00:00, 47.59it/s, loss=3.95, v_num=2, val_loss=3.5, val_acc=0.281]\n",
            "Epoch 3: 100% 4/4 [00:00<00:00, 29.25it/s, loss=3.95, v_num=2, val_loss=3.04, val_acc=0.328]\n",
            "Epoch 4:  50% 2/4 [00:00<00:00, 47.08it/s, loss=3.75, v_num=2, val_loss=3.04, val_acc=0.328]\n",
            "Epoch 4: 100% 4/4 [00:00<00:00, 29.90it/s, loss=3.75, v_num=2, val_loss=2.53, val_acc=0.449]\n",
            "Epoch 5:  50% 2/4 [00:00<00:00, 46.56it/s, loss=3.53, v_num=2, val_loss=2.53, val_acc=0.449]\n",
            "Epoch 5: 100% 4/4 [00:00<00:00, 28.74it/s, loss=3.53, v_num=2, val_loss=2.04, val_acc=0.547]\n",
            "Epoch 6:  50% 2/4 [00:00<00:00, 46.93it/s, loss=3.3, v_num=2, val_loss=2.04, val_acc=0.547] \n",
            "Epoch 6: 100% 4/4 [00:00<00:00, 29.33it/s, loss=3.3, v_num=2, val_loss=1.61, val_acc=0.656]\n",
            "Epoch 7:  50% 2/4 [00:00<00:00, 45.33it/s, loss=3.08, v_num=2, val_loss=1.61, val_acc=0.656]\n",
            "Epoch 7: 100% 4/4 [00:00<00:00, 28.89it/s, loss=3.08, v_num=2, val_loss=1.23, val_acc=0.711]\n",
            "Epoch 8:  50% 2/4 [00:00<00:00, 47.21it/s, loss=2.87, v_num=2, val_loss=1.23, val_acc=0.711]\n",
            "Epoch 8: 100% 4/4 [00:00<00:00, 29.72it/s, loss=2.87, v_num=2, val_loss=0.91, val_acc=0.785]\n",
            "Epoch 9:  50% 2/4 [00:00<00:00, 46.93it/s, loss=2.67, v_num=2, val_loss=0.91, val_acc=0.785]\n",
            "Epoch 9: 100% 4/4 [00:00<00:00, 29.42it/s, loss=2.67, v_num=2, val_loss=0.653, val_acc=0.844]\n",
            "Epoch 10:  50% 2/4 [00:00<00:00, 47.51it/s, loss=2.29, v_num=2, val_loss=0.653, val_acc=0.844]\n",
            "Epoch 10: 100% 4/4 [00:00<00:00, 29.54it/s, loss=2.29, v_num=2, val_loss=0.43, val_acc=0.922] \n",
            "Epoch 11:  50% 2/4 [00:00<00:00, 47.81it/s, loss=1.91, v_num=2, val_loss=0.43, val_acc=0.922]\n",
            "Epoch 11: 100% 4/4 [00:00<00:00, 30.03it/s, loss=1.91, v_num=2, val_loss=0.279, val_acc=0.938]\n",
            "Epoch 12:  50% 2/4 [00:00<00:00, 45.94it/s, loss=1.56, v_num=2, val_loss=0.279, val_acc=0.938]\n",
            "Epoch 12: 100% 4/4 [00:00<00:00, 28.79it/s, loss=1.56, v_num=2, val_loss=0.168, val_acc=0.98] \n",
            "Epoch 13:  50% 2/4 [00:00<00:00, 47.42it/s, loss=1.23, v_num=2, val_loss=0.168, val_acc=0.98]\n",
            "Epoch 13: 100% 4/4 [00:00<00:00, 29.26it/s, loss=1.23, v_num=2, val_loss=0.105, val_acc=0.988]\n",
            "Epoch 14:  50% 2/4 [00:00<00:00, 46.94it/s, loss=0.952, v_num=2, val_loss=0.105, val_acc=0.988]\n",
            "Epoch 14: 100% 4/4 [00:00<00:00, 28.89it/s, loss=0.952, v_num=2, val_loss=0.0691, val_acc=0.996]\n",
            "Epoch 15:  50% 2/4 [00:00<00:00, 46.76it/s, loss=0.716, v_num=2, val_loss=0.0691, val_acc=0.996]\n",
            "Epoch 15: 100% 4/4 [00:00<00:00, 29.18it/s, loss=0.716, v_num=2, val_loss=0.0411, val_acc=0.996]\n",
            "Epoch 16:  50% 2/4 [00:00<00:00, 47.07it/s, loss=0.525, v_num=2, val_loss=0.0411, val_acc=0.996]\n",
            "Epoch 16: 100% 4/4 [00:00<00:00, 27.90it/s, loss=0.525, v_num=2, val_loss=0.028, val_acc=0.996] \n",
            "Epoch 17:  50% 2/4 [00:00<00:00, 47.23it/s, loss=0.374, v_num=2, val_loss=0.028, val_acc=0.996]\n",
            "Epoch 17: 100% 4/4 [00:00<00:00, 29.51it/s, loss=0.374, v_num=2, val_loss=0.0189, val_acc=1]   \n",
            "Epoch 18:  50% 2/4 [00:00<00:00, 46.45it/s, loss=0.26, v_num=2, val_loss=0.0189, val_acc=1] \n",
            "Epoch 18: 100% 4/4 [00:00<00:00, 29.12it/s, loss=0.26, v_num=2, val_loss=0.0163, val_acc=1]\n",
            "Epoch 19:  50% 2/4 [00:00<00:00, 46.03it/s, loss=0.177, v_num=2, val_loss=0.0163, val_acc=1]\n",
            "Epoch 19: 100% 4/4 [00:00<00:00, 29.57it/s, loss=0.177, v_num=2, val_loss=0.0127, val_acc=1]\n",
            "Epoch 20:  50% 2/4 [00:00<00:00, 44.88it/s, loss=0.116, v_num=2, val_loss=0.0127, val_acc=1]\n",
            "Epoch 20: 100% 4/4 [00:00<00:00, 28.69it/s, loss=0.116, v_num=2, val_loss=0.0112, val_acc=1]\n",
            "Epoch 21:  50% 2/4 [00:00<00:00, 47.02it/s, loss=0.0761, v_num=2, val_loss=0.0112, val_acc=1]\n",
            "Epoch 21: 100% 4/4 [00:00<00:00, 59.41it/s, loss=0.0761, v_num=2, val_loss=0.0147, val_acc=0.996]\n",
            "Epoch 22:  50% 2/4 [00:00<00:00, 45.96it/s, loss=0.0511, v_num=2, val_loss=0.0147, val_acc=0.996]\n",
            "Epoch 22: 100% 4/4 [00:00<00:00, 58.53it/s, loss=0.0511, v_num=2, val_loss=0.0184, val_acc=0.996]\n",
            "Epoch 23:  50% 2/4 [00:00<00:00, 45.26it/s, loss=0.0385, v_num=2, val_loss=0.0184, val_acc=0.996]\n",
            "Epoch 23: 100% 4/4 [00:00<00:00, 59.86it/s, loss=0.0385, v_num=2, val_loss=0.0168, val_acc=0.996]\n",
            "Epoch 24:  50% 2/4 [00:00<00:00, 51.87it/s, loss=0.0289, v_num=2, val_loss=0.0168, val_acc=0.996]\n",
            "Epoch 24: 100% 4/4 [00:00<00:00, 30.36it/s, loss=0.0289, v_num=2, val_loss=0.00791, val_acc=0.996]\n",
            "Epoch 25:  50% 2/4 [00:00<00:00, 51.39it/s, loss=0.0232, v_num=2, val_loss=0.00791, val_acc=0.996]\n",
            "Epoch 25: 100% 4/4 [00:00<00:00, 65.46it/s, loss=0.0232, v_num=2, val_loss=0.00826, val_acc=1]    \n",
            "Epoch 26:  50% 2/4 [00:00<00:00, 53.42it/s, loss=0.0204, v_num=2, val_loss=0.00826, val_acc=1]\n",
            "Epoch 26: 100% 4/4 [00:00<00:00, 63.39it/s, loss=0.0204, v_num=2, val_loss=0.0289, val_acc=0.992]\n",
            "Epoch 27:  50% 2/4 [00:00<00:00, 51.97it/s, loss=0.0188, v_num=2, val_loss=0.0289, val_acc=0.992]\n",
            "Epoch 27: 100% 4/4 [00:00<00:00, 62.13it/s, loss=0.0188, v_num=2, val_loss=0.00807, val_acc=0.996]\n",
            "Epoch 28:  50% 2/4 [00:00<00:00, 44.50it/s, loss=0.0183, v_num=2, val_loss=0.00807, val_acc=0.996]\n",
            "Epoch 28: 100% 4/4 [00:00<00:00, 59.75it/s, loss=0.0183, v_num=2, val_loss=0.0263, val_acc=0.988] \n",
            "Epoch 29:  50% 2/4 [00:00<00:00, 54.50it/s, loss=0.0186, v_num=2, val_loss=0.0263, val_acc=0.988]\n",
            "Epoch 29: 100% 4/4 [00:00<00:00, 31.44it/s, loss=0.0186, v_num=2, val_loss=0.00253, val_acc=1]   \n",
            "Epoch 30:  50% 2/4 [00:00<00:00, 53.53it/s, loss=0.018, v_num=2, val_loss=0.00253, val_acc=1] \n",
            "Epoch 30: 100% 4/4 [00:00<00:00, 67.25it/s, loss=0.018, v_num=2, val_loss=0.0191, val_acc=0.992]\n",
            "Epoch 31:  50% 2/4 [00:00<00:00, 54.67it/s, loss=0.0185, v_num=2, val_loss=0.0191, val_acc=0.992]\n",
            "Epoch 31: 100% 4/4 [00:00<00:00, 30.51it/s, loss=0.0185, v_num=2, val_loss=0.00182, val_acc=1]   \n",
            "Epoch 32:  50% 2/4 [00:00<00:00, 50.80it/s, loss=0.0176, v_num=2, val_loss=0.00182, val_acc=1]\n",
            "Epoch 32: 100% 4/4 [00:00<00:00, 64.57it/s, loss=0.0176, v_num=2, val_loss=0.00494, val_acc=1]\n",
            "Epoch 33:  50% 2/4 [00:00<00:00, 55.45it/s, loss=0.0139, v_num=2, val_loss=0.00494, val_acc=1]\n",
            "Epoch 33: 100% 4/4 [00:00<00:00, 31.03it/s, loss=0.0139, v_num=2, val_loss=0.00108, val_acc=1]\n",
            "Epoch 34:  50% 2/4 [00:00<00:00, 54.23it/s, loss=0.0129, v_num=2, val_loss=0.00108, val_acc=1]\n",
            "Epoch 34: 100% 4/4 [00:00<00:00, 68.44it/s, loss=0.0129, v_num=2, val_loss=0.00272, val_acc=1]\n",
            "Epoch 35:  50% 2/4 [00:00<00:00, 55.94it/s, loss=0.0121, v_num=2, val_loss=0.00272, val_acc=1]\n",
            "Epoch 35: 100% 4/4 [00:00<00:00, 69.59it/s, loss=0.0121, v_num=2, val_loss=0.0115, val_acc=0.992]\n",
            "Epoch 36:  50% 2/4 [00:00<00:00, 51.81it/s, loss=0.0118, v_num=2, val_loss=0.0115, val_acc=0.992]\n",
            "Epoch 36: 100% 4/4 [00:00<00:00, 66.04it/s, loss=0.0118, v_num=2, val_loss=0.00155, val_acc=1]   \n",
            "Epoch 37:  50% 2/4 [00:00<00:00, 54.41it/s, loss=0.0104, v_num=2, val_loss=0.00155, val_acc=1]\n",
            "Epoch 37: 100% 4/4 [00:00<00:00, 68.69it/s, loss=0.0104, v_num=2, val_loss=0.00276, val_acc=1]\n",
            "Epoch 38:  50% 2/4 [00:00<00:00, 56.65it/s, loss=0.0105, v_num=2, val_loss=0.00276, val_acc=1] \n",
            "Epoch 38: 100% 4/4 [00:00<00:00, 70.16it/s, loss=0.0105, v_num=2, val_loss=0.00132, val_acc=1]\n",
            "Epoch 39:  50% 2/4 [00:00<00:00, 55.72it/s, loss=0.00861, v_num=2, val_loss=0.00132, val_acc=1]\n",
            "Epoch 39: 100% 4/4 [00:00<00:00, 68.86it/s, loss=0.00861, v_num=2, val_loss=0.00845, val_acc=1]\n",
            "Epoch 40:  50% 2/4 [00:00<00:00, 53.84it/s, loss=0.0113, v_num=2, val_loss=0.00845, val_acc=1] \n",
            "Epoch 40: 100% 4/4 [00:00<00:00, 68.39it/s, loss=0.0113, v_num=2, val_loss=0.00147, val_acc=1]\n",
            "Epoch 41:  50% 2/4 [00:00<00:00, 52.33it/s, loss=0.0101, v_num=2, val_loss=0.00147, val_acc=1]\n",
            "Epoch 41: 100% 4/4 [00:00<00:00, 65.83it/s, loss=0.0101, v_num=2, val_loss=0.00218, val_acc=1]\n",
            "Epoch 42:  50% 2/4 [00:00<00:00, 58.88it/s, loss=0.0109, v_num=2, val_loss=0.00218, val_acc=1]\n",
            "Epoch 42: 100% 4/4 [00:00<00:00, 71.58it/s, loss=0.0109, v_num=2, val_loss=0.0155, val_acc=0.996]\n",
            "Epoch 43:  50% 2/4 [00:00<00:00, 56.51it/s, loss=0.0115, v_num=2, val_loss=0.0155, val_acc=0.996]\n",
            "Epoch 43: 100% 4/4 [00:00<00:00, 71.21it/s, loss=0.0115, v_num=2, val_loss=0.00267, val_acc=1]   \n",
            "Epoch 43: 100% 4/4 [00:00<00:00, 67.74it/s, loss=0.0115, v_num=2, val_loss=0.00267, val_acc=1]\n",
            "Testing: 100% 2/2 [00:00<00:00, 98.20it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(1., device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoLHRA-dTn0y",
        "outputId": "eff99906-5509-44ad-9e49-787ea2d8f718"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1 --num_workers=4\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-27 02:31:01.258599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:26<00:06, 75.36it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2040/2542 [00:27<00:06, 75.08it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2054/2542 [00:27<00:06, 75.31it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2068/2542 [00:27<00:06, 75.54it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2083/2542 [00:27<00:06, 75.80it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2099/2542 [00:27<00:05, 76.09it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2115/2542 [00:27<00:05, 76.38it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2131/2542 [00:27<00:05, 76.65it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2147/2542 [00:27<00:05, 76.93it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2163/2542 [00:28<00:04, 77.20it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2179/2542 [00:28<00:04, 77.46it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2195/2542 [00:28<00:04, 77.73it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  32% 162/509 [00:01<00:03, 104.50it/s]\u001b[A\n",
            "Epoch 0:  87% 2211/2542 [00:28<00:04, 77.99it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2227/2542 [00:28<00:04, 78.23it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2243/2542 [00:28<00:03, 78.49it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2259/2542 [00:28<00:03, 78.76it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2275/2542 [00:28<00:03, 78.97it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2291/2542 [00:28<00:03, 79.23it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2307/2542 [00:29<00:02, 79.48it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2323/2542 [00:29<00:02, 79.71it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2339/2542 [00:29<00:02, 79.96it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2355/2542 [00:29<00:02, 80.21it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2371/2542 [00:29<00:02, 80.43it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2387/2542 [00:29<00:01, 80.69it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2403/2542 [00:29<00:01, 80.91it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2419/2542 [00:29<00:01, 81.14it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2435/2542 [00:29<00:01, 81.39it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2451/2542 [00:30<00:01, 81.63it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2467/2542 [00:30<00:00, 81.84it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2483/2542 [00:30<00:00, 82.06it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  88% 450/509 [00:03<00:00, 141.72it/s]\u001b[A\n",
            "Epoch 0:  98% 2499/2542 [00:30<00:00, 82.29it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2515/2542 [00:30<00:00, 82.50it/s, loss=0.57, v_num=3, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:30<00:00, 82.42it/s, loss=0.57, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:26<00:06, 75.51it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 1/509 [00:00<01:20,  6.28it/s]\u001b[A\n",
            "Epoch 1:  81% 2048/2542 [00:27<00:06, 75.33it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2064/2542 [00:27<00:06, 75.61it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2080/2542 [00:27<00:06, 75.90it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2096/2542 [00:27<00:05, 76.20it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  83% 2112/2542 [00:27<00:05, 76.47it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2128/2542 [00:27<00:05, 76.74it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2144/2542 [00:27<00:05, 77.01it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2160/2542 [00:27<00:04, 77.27it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2176/2542 [00:28<00:04, 77.52it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2192/2542 [00:28<00:04, 77.77it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2208/2542 [00:28<00:04, 78.04it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2224/2542 [00:28<00:04, 78.29it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2240/2542 [00:28<00:03, 78.56it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  41% 207/509 [00:01<00:02, 125.12it/s]\u001b[A\n",
            "Epoch 1:  89% 2256/2542 [00:28<00:03, 78.80it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2272/2542 [00:28<00:03, 79.03it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2288/2542 [00:28<00:03, 79.28it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2304/2542 [00:28<00:02, 79.51it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2320/2542 [00:29<00:02, 79.76it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2336/2542 [00:29<00:02, 80.01it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2352/2542 [00:29<00:02, 80.24it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2368/2542 [00:29<00:02, 80.48it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2384/2542 [00:29<00:01, 80.71it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2400/2542 [00:29<00:01, 80.95it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  95% 2416/2542 [00:29<00:01, 81.19it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2432/2542 [00:29<00:01, 81.43it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2448/2542 [00:29<00:01, 81.65it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  97% 2464/2542 [00:30<00:00, 81.87it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2480/2542 [00:30<00:00, 82.09it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2496/2542 [00:30<00:00, 82.32it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  91% 463/509 [00:03<00:00, 142.48it/s]\u001b[A\n",
            "Epoch 1:  99% 2512/2542 [00:30<00:00, 82.55it/s, loss=0.508, v_num=3, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2542/2542 [00:30<00:00, 82.52it/s, loss=0.508, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:26<00:06, 75.91it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 1/509 [00:00<01:10,  7.21it/s]\u001b[A\n",
            "Epoch 2:  81% 2048/2542 [00:27<00:06, 75.76it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2064/2542 [00:27<00:06, 76.05it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2080/2542 [00:27<00:06, 76.33it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2096/2542 [00:27<00:05, 76.61it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2112/2542 [00:27<00:05, 76.88it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2128/2542 [00:27<00:05, 77.14it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2144/2542 [00:27<00:05, 77.43it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2160/2542 [00:27<00:04, 77.70it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2176/2542 [00:27<00:04, 77.96it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2192/2542 [00:28<00:04, 78.23it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2208/2542 [00:28<00:04, 78.49it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  87% 2224/2542 [00:28<00:04, 78.75it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2240/2542 [00:28<00:03, 79.02it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2256/2542 [00:28<00:03, 79.25it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2272/2542 [00:28<00:03, 79.51it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2288/2542 [00:28<00:03, 79.75it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2304/2542 [00:28<00:02, 80.00it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2320/2542 [00:28<00:02, 80.25it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2336/2542 [00:29<00:02, 80.49it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2352/2542 [00:29<00:02, 80.74it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  63% 319/509 [00:02<00:01, 143.28it/s]\u001b[A\n",
            "Epoch 2:  93% 2368/2542 [00:29<00:02, 80.98it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2384/2542 [00:29<00:01, 81.22it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2400/2542 [00:29<00:01, 81.44it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2416/2542 [00:29<00:01, 81.68it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2432/2542 [00:29<00:01, 81.92it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2448/2542 [00:29<00:01, 82.13it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2464/2542 [00:29<00:00, 82.36it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2480/2542 [00:30<00:00, 82.57it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2496/2542 [00:30<00:00, 82.81it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2512/2542 [00:30<00:00, 83.05it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2528/2542 [00:30<00:00, 83.27it/s, loss=0.463, v_num=3, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:30<00:00, 82.99it/s, loss=0.463, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2033/2542 [00:26<00:06, 75.70it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  81% 2048/2542 [00:27<00:06, 75.52it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating:   3% 15/509 [00:00<00:58,  8.40it/s]\u001b[A\n",
            "Epoch 3:  81% 2064/2542 [00:27<00:06, 75.77it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2080/2542 [00:27<00:06, 76.04it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2096/2542 [00:27<00:05, 76.32it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2112/2542 [00:27<00:05, 76.60it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2128/2542 [00:27<00:05, 76.85it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2144/2542 [00:27<00:05, 77.13it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2160/2542 [00:27<00:04, 77.39it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2176/2542 [00:28<00:04, 77.66it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2192/2542 [00:28<00:04, 77.89it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2208/2542 [00:28<00:04, 78.16it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2224/2542 [00:28<00:04, 78.42it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2240/2542 [00:28<00:03, 78.68it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2256/2542 [00:28<00:03, 78.94it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2272/2542 [00:28<00:03, 79.18it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  47% 239/509 [00:01<00:02, 134.56it/s]\u001b[A\n",
            "Epoch 3:  90% 2288/2542 [00:28<00:03, 79.44it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2304/2542 [00:28<00:02, 79.70it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2320/2542 [00:29<00:02, 79.95it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2336/2542 [00:29<00:02, 80.17it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2352/2542 [00:29<00:02, 80.40it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2368/2542 [00:29<00:02, 80.62it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2384/2542 [00:29<00:01, 80.85it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2400/2542 [00:29<00:01, 81.11it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  95% 2416/2542 [00:29<00:01, 81.34it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2432/2542 [00:29<00:01, 81.57it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2448/2542 [00:29<00:01, 81.81it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2464/2542 [00:30<00:00, 82.03it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2480/2542 [00:30<00:00, 82.28it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2496/2542 [00:30<00:00, 82.48it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2512/2542 [00:30<00:00, 82.72it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2528/2542 [00:30<00:00, 82.93it/s, loss=0.437, v_num=3, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:30<00:00, 82.69it/s, loss=0.437, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2033/2542 [00:26<00:06, 75.58it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  81% 2048/2542 [00:27<00:06, 75.42it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2064/2542 [00:27<00:06, 75.71it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:   6% 31/509 [00:00<00:39, 11.99it/s]\u001b[A\n",
            "Epoch 4:  82% 2080/2542 [00:27<00:06, 75.98it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2096/2542 [00:27<00:05, 76.26it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2112/2542 [00:27<00:05, 76.46it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2128/2542 [00:27<00:05, 76.74it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2144/2542 [00:27<00:05, 77.01it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  85% 2160/2542 [00:27<00:04, 77.27it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2176/2542 [00:28<00:04, 77.51it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2193/2542 [00:28<00:04, 77.83it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2210/2542 [00:28<00:04, 78.09it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  35% 177/509 [00:01<00:03, 108.80it/s]\u001b[A\n",
            "Epoch 4:  88% 2227/2542 [00:28<00:04, 78.36it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2244/2542 [00:28<00:03, 78.64it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2261/2542 [00:28<00:03, 78.88it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2278/2542 [00:28<00:03, 79.15it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2295/2542 [00:28<00:03, 79.42it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2312/2542 [00:29<00:02, 79.66it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2329/2542 [00:29<00:02, 79.93it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2346/2542 [00:29<00:02, 80.17it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2363/2542 [00:29<00:02, 80.42it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  65% 330/509 [00:02<00:01, 141.12it/s]\u001b[A\n",
            "Epoch 4:  94% 2380/2542 [00:29<00:02, 80.67it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2397/2542 [00:29<00:01, 80.91it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  95% 2414/2542 [00:29<00:01, 81.15it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2431/2542 [00:29<00:01, 81.40it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2448/2542 [00:29<00:01, 81.66it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2465/2542 [00:30<00:00, 81.89it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2482/2542 [00:30<00:00, 82.10it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  88% 450/509 [00:03<00:00, 139.05it/s]\u001b[A\n",
            "Epoch 4:  98% 2499/2542 [00:30<00:00, 82.34it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2516/2542 [00:30<00:00, 82.59it/s, loss=0.408, v_num=3, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 82.73it/s, loss=0.408, v_num=3, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 82.25it/s, loss=0.408, v_num=3, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:03<00:00, 134.02it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8061, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOqKjwMHVbKn",
        "outputId": "22db0a6e-cad7-4e3d-8bc3-bc068374ee78"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1 --num_workers=4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-27 02:34:11.749315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:26<00:06, 75.58it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2037/2542 [00:27<00:06, 75.24it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2050/2542 [00:27<00:06, 75.43it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2066/2542 [00:27<00:06, 75.72it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2082/2542 [00:27<00:06, 76.00it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2098/2542 [00:27<00:05, 76.29it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2114/2542 [00:27<00:05, 76.57it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2130/2542 [00:27<00:05, 76.86it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2146/2542 [00:27<00:05, 77.12it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2162/2542 [00:27<00:04, 77.39it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2178/2542 [00:28<00:04, 77.63it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2194/2542 [00:28<00:04, 77.92it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2210/2542 [00:28<00:04, 78.16it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  35% 177/509 [00:01<00:02, 113.55it/s]\u001b[A\n",
            "Epoch 0:  88% 2226/2542 [00:28<00:04, 78.41it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2242/2542 [00:28<00:03, 78.67it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2258/2542 [00:28<00:03, 78.92it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2274/2542 [00:28<00:03, 79.16it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2290/2542 [00:28<00:03, 79.41it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2306/2542 [00:28<00:02, 79.63it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2322/2542 [00:29<00:02, 79.88it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2338/2542 [00:29<00:02, 80.14it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2354/2542 [00:29<00:02, 80.37it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2370/2542 [00:29<00:02, 80.62it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2386/2542 [00:29<00:01, 80.87it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2402/2542 [00:29<00:01, 81.10it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2418/2542 [00:29<00:01, 81.33it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2434/2542 [00:29<00:01, 81.53it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2450/2542 [00:29<00:01, 81.78it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  97% 2466/2542 [00:30<00:00, 82.00it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2482/2542 [00:30<00:00, 82.24it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2498/2542 [00:30<00:00, 82.46it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  91% 465/509 [00:03<00:00, 142.36it/s]\u001b[A\n",
            "Epoch 0:  99% 2514/2542 [00:30<00:00, 82.67it/s, loss=0.57, v_num=4, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:30<00:00, 82.57it/s, loss=0.57, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:26<00:06, 75.32it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 1/509 [00:00<01:22,  6.16it/s]\u001b[A\n",
            "Epoch 1:  81% 2048/2542 [00:27<00:06, 75.12it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2064/2542 [00:27<00:06, 75.39it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2080/2542 [00:27<00:06, 75.65it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2096/2542 [00:27<00:05, 75.93it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  83% 2112/2542 [00:27<00:05, 76.23it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2128/2542 [00:27<00:05, 76.51it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2144/2542 [00:27<00:05, 76.77it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2160/2542 [00:28<00:04, 77.04it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2176/2542 [00:28<00:04, 77.32it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2192/2542 [00:28<00:04, 77.57it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2209/2542 [00:28<00:04, 77.87it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2226/2542 [00:28<00:04, 78.11it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2243/2542 [00:28<00:03, 78.36it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2260/2542 [00:28<00:03, 78.65it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  45% 227/509 [00:01<00:02, 128.64it/s]\u001b[A\n",
            "Epoch 1:  90% 2277/2542 [00:28<00:03, 78.92it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2294/2542 [00:28<00:03, 79.19it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2311/2542 [00:29<00:02, 79.44it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2328/2542 [00:29<00:02, 79.70it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2345/2542 [00:29<00:02, 79.95it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  93% 2362/2542 [00:29<00:02, 80.25it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2379/2542 [00:29<00:02, 80.47it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2396/2542 [00:29<00:01, 80.72it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  72% 364/509 [00:02<00:01, 141.76it/s]\u001b[A\n",
            "Epoch 1:  95% 2413/2542 [00:29<00:01, 80.97it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2430/2542 [00:29<00:01, 81.22it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2447/2542 [00:30<00:01, 81.49it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  97% 2464/2542 [00:30<00:00, 81.72it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2481/2542 [00:30<00:00, 81.97it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2498/2542 [00:30<00:00, 82.20it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2515/2542 [00:30<00:00, 82.44it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2532/2542 [00:30<00:00, 82.66it/s, loss=0.508, v_num=4, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2542/2542 [00:30<00:00, 82.37it/s, loss=0.508, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:26<00:06, 75.34it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  80% 2040/2542 [00:27<00:06, 75.02it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2057/2542 [00:27<00:06, 75.30it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2074/2542 [00:27<00:06, 75.58it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Validating:   8% 41/509 [00:00<00:26, 17.63it/s]\u001b[A\n",
            "Epoch 2:  82% 2091/2542 [00:27<00:05, 75.90it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  83% 2108/2542 [00:27<00:05, 76.18it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2125/2542 [00:27<00:05, 76.49it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2142/2542 [00:27<00:05, 76.75it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2159/2542 [00:28<00:04, 77.02it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2176/2542 [00:28<00:04, 77.30it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2193/2542 [00:28<00:04, 77.57it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  31% 160/509 [00:01<00:03, 100.24it/s]\u001b[A\n",
            "Epoch 2:  87% 2210/2542 [00:28<00:04, 77.83it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2227/2542 [00:28<00:04, 78.13it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2244/2542 [00:28<00:03, 78.40it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2261/2542 [00:28<00:03, 78.68it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2278/2542 [00:28<00:03, 78.96it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2295/2542 [00:28<00:03, 79.20it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2312/2542 [00:29<00:02, 79.47it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2329/2542 [00:29<00:02, 79.75it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  58% 296/509 [00:02<00:01, 141.69it/s]\u001b[A\n",
            "Epoch 2:  92% 2346/2542 [00:29<00:02, 79.99it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2363/2542 [00:29<00:02, 80.24it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2380/2542 [00:29<00:02, 80.46it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2397/2542 [00:29<00:01, 80.70it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2414/2542 [00:29<00:01, 80.95it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2431/2542 [00:29<00:01, 81.19it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2448/2542 [00:30<00:01, 81.43it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2465/2542 [00:30<00:00, 81.68it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2482/2542 [00:30<00:00, 81.92it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  88% 449/509 [00:03<00:00, 141.81it/s]\u001b[A\n",
            "Epoch 2:  98% 2499/2542 [00:30<00:00, 82.14it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2516/2542 [00:30<00:00, 82.39it/s, loss=0.463, v_num=4, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:30<00:00, 82.29it/s, loss=0.463, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2033/2542 [00:27<00:06, 74.67it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  80% 2040/2542 [00:27<00:06, 74.32it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  81% 2057/2542 [00:27<00:06, 74.62it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2074/2542 [00:27<00:06, 74.91it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2091/2542 [00:27<00:05, 75.23it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  12% 60/509 [00:00<00:19, 22.87it/s]\u001b[A\n",
            "Epoch 3:  83% 2108/2542 [00:27<00:05, 75.50it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2125/2542 [00:28<00:05, 75.78it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2142/2542 [00:28<00:05, 76.07it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2159/2542 [00:28<00:05, 76.32it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2176/2542 [00:28<00:04, 76.58it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2193/2542 [00:28<00:04, 76.85it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  31% 160/509 [00:01<00:03, 97.26it/s]\u001b[A\n",
            "Epoch 3:  87% 2210/2542 [00:28<00:04, 77.12it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2227/2542 [00:28<00:04, 76.97it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  88% 2244/2542 [00:29<00:03, 77.23it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  89% 2261/2542 [00:29<00:03, 77.48it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2278/2542 [00:29<00:03, 77.73it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  48% 245/509 [00:02<00:02, 119.61it/s]\u001b[A\n",
            "Epoch 3:  90% 2295/2542 [00:29<00:03, 77.98it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2312/2542 [00:29<00:02, 78.21it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2329/2542 [00:29<00:02, 78.48it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2346/2542 [00:29<00:02, 78.74it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2363/2542 [00:29<00:02, 78.96it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  65% 332/509 [00:02<00:01, 135.37it/s]\u001b[A\n",
            "Epoch 3:  94% 2380/2542 [00:30<00:02, 79.20it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2397/2542 [00:30<00:01, 79.45it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  95% 2414/2542 [00:30<00:01, 79.67it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2431/2542 [00:30<00:01, 79.90it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2448/2542 [00:30<00:01, 80.14it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2465/2542 [00:30<00:00, 80.41it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2482/2542 [00:30<00:00, 80.64it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2499/2542 [00:30<00:00, 80.88it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  92% 466/509 [00:03<00:00, 141.90it/s]\u001b[A\n",
            "Epoch 3:  99% 2516/2542 [00:31<00:00, 81.12it/s, loss=0.437, v_num=4, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:31<00:00, 81.03it/s, loss=0.437, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2033/2542 [00:27<00:06, 74.65it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  80% 2040/2542 [00:27<00:06, 74.31it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2057/2542 [00:27<00:06, 74.60it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2074/2542 [00:27<00:06, 74.89it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2091/2542 [00:27<00:05, 75.18it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  12% 59/509 [00:00<00:21, 20.64it/s]\u001b[A\n",
            "Epoch 4:  83% 2108/2542 [00:27<00:05, 75.45it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2125/2542 [00:28<00:05, 75.74it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2142/2542 [00:28<00:05, 76.03it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  85% 2159/2542 [00:28<00:05, 76.30it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2176/2542 [00:28<00:04, 76.59it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2193/2542 [00:28<00:04, 76.87it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  32% 161/509 [00:01<00:03, 96.54it/s]\u001b[A\n",
            "Epoch 4:  87% 2210/2542 [00:28<00:04, 77.14it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2227/2542 [00:28<00:04, 77.40it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2244/2542 [00:28<00:03, 77.70it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2261/2542 [00:29<00:03, 77.95it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2278/2542 [00:29<00:03, 78.20it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2295/2542 [00:29<00:03, 78.41it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  91% 2312/2542 [00:29<00:02, 78.65it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  55% 279/509 [00:02<00:01, 129.30it/s]\u001b[A\n",
            "Epoch 4:  92% 2329/2542 [00:29<00:02, 78.92it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2346/2542 [00:29<00:02, 79.17it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2363/2542 [00:29<00:02, 79.40it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2380/2542 [00:29<00:02, 79.65it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2397/2542 [00:30<00:01, 79.89it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  95% 2414/2542 [00:30<00:01, 80.13it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  75% 381/509 [00:02<00:00, 138.05it/s]\u001b[A\n",
            "Epoch 4:  96% 2431/2542 [00:30<00:01, 80.37it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2448/2542 [00:30<00:01, 80.55it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2465/2542 [00:30<00:00, 80.79it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2482/2542 [00:30<00:00, 81.04it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2499/2542 [00:30<00:00, 81.27it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  92% 467/509 [00:03<00:00, 137.35it/s]\u001b[A\n",
            "Epoch 4:  99% 2516/2542 [00:30<00:00, 81.52it/s, loss=0.408, v_num=4, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:31<00:00, 81.67it/s, loss=0.408, v_num=4, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:31<00:00, 81.21it/s, loss=0.408, v_num=4, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:03<00:00, 134.09it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8061, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HZsLjz4XfTj",
        "outputId": "3f138bf8-004e-4178-e2ca-85653e2d871c"
      },
      "source": [
        "\n",
        "!python3 training/run_experiment.py --model_class=CNN --data_class=EMNIST --max_epochs=5 --gpus=1 --num_workers=4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-02-27 02:44:00.716474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "   | Name             | Type      | Params\n",
            "------------------------------------------------\n",
            "0  | model            | CNN       | 1.7 M \n",
            "1  | model.conv1      | ConvBlock | 640   \n",
            "2  | model.conv1.conv | Conv2d    | 640   \n",
            "3  | model.conv1.relu | ReLU      | 0     \n",
            "4  | model.conv2      | ConvBlock | 36.9 K\n",
            "5  | model.conv2.conv | Conv2d    | 36.9 K\n",
            "6  | model.conv2.relu | ReLU      | 0     \n",
            "7  | model.dropout    | Dropout   | 0     \n",
            "8  | model.max_pool   | MaxPool2d | 0     \n",
            "9  | model.fc1        | Linear    | 1.6 M \n",
            "10 | model.fc2        | Linear    | 10.7 K\n",
            "11 | train_acc        | Accuracy  | 0     \n",
            "12 | val_acc          | Accuracy  | 0     \n",
            "13 | test_acc         | Accuracy  | 0     \n",
            "------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  80% 2033/2542 [00:26<00:06, 76.13it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  80% 2039/2542 [00:26<00:06, 75.79it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2054/2542 [00:27<00:06, 76.04it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  81% 2069/2542 [00:27<00:06, 76.31it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  82% 2084/2542 [00:27<00:05, 76.56it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2100/2542 [00:27<00:05, 76.84it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  83% 2116/2542 [00:27<00:05, 77.12it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  84% 2132/2542 [00:27<00:05, 77.38it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2148/2542 [00:27<00:05, 77.63it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  85% 2164/2542 [00:27<00:04, 77.91it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  86% 2180/2542 [00:27<00:04, 78.16it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  29% 147/509 [00:01<00:04, 85.61it/s]\u001b[A\n",
            "Epoch 0:  86% 2196/2542 [00:28<00:04, 78.40it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  87% 2212/2542 [00:28<00:04, 78.65it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2228/2542 [00:28<00:03, 78.90it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  88% 2245/2542 [00:28<00:03, 79.21it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  89% 2262/2542 [00:28<00:03, 79.43it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2279/2542 [00:28<00:03, 79.65it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  90% 2296/2542 [00:28<00:03, 79.92it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  91% 2313/2542 [00:28<00:02, 80.19it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  55% 281/509 [00:02<00:01, 138.57it/s]\u001b[A\n",
            "Epoch 0:  92% 2330/2542 [00:28<00:02, 80.45it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  92% 2347/2542 [00:29<00:02, 80.69it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  93% 2364/2542 [00:29<00:02, 80.93it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2381/2542 [00:29<00:01, 81.19it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  94% 2398/2542 [00:29<00:01, 81.44it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  95% 2415/2542 [00:29<00:01, 81.66it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2432/2542 [00:29<00:01, 81.92it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  96% 2449/2542 [00:29<00:01, 82.16it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Validating:  82% 416/509 [00:03<00:00, 142.65it/s]\u001b[A\n",
            "Epoch 0:  97% 2466/2542 [00:29<00:00, 82.43it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2483/2542 [00:30<00:00, 82.66it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  98% 2500/2542 [00:30<00:00, 82.90it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0:  99% 2517/2542 [00:30<00:00, 83.15it/s, loss=0.57, v_num=6, val_loss=4.41, val_acc=0.0195]\n",
            "Epoch 0: 100% 2542/2542 [00:30<00:00, 82.99it/s, loss=0.57, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  80% 2033/2542 [00:26<00:06, 75.96it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  80% 2040/2542 [00:26<00:06, 75.60it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  81% 2057/2542 [00:27<00:06, 75.91it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2074/2542 [00:27<00:06, 76.20it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  82% 2091/2542 [00:27<00:05, 76.49it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  12% 59/509 [00:00<00:20, 22.27it/s]\u001b[A\n",
            "Epoch 1:  83% 2108/2542 [00:27<00:05, 76.75it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2125/2542 [00:27<00:05, 77.04it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  84% 2142/2542 [00:27<00:05, 77.34it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  85% 2159/2542 [00:27<00:04, 77.62it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2176/2542 [00:27<00:04, 77.90it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  86% 2193/2542 [00:28<00:04, 78.17it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  87% 2210/2542 [00:28<00:04, 78.43it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  35% 178/509 [00:01<00:03, 108.55it/s]\u001b[A\n",
            "Epoch 1:  88% 2227/2542 [00:28<00:04, 78.65it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  88% 2244/2542 [00:28<00:03, 78.91it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  89% 2261/2542 [00:28<00:03, 79.17it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2278/2542 [00:28<00:03, 79.46it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  90% 2295/2542 [00:28<00:03, 79.72it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  91% 2312/2542 [00:28<00:02, 79.97it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2329/2542 [00:29<00:02, 80.24it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  92% 2346/2542 [00:29<00:02, 80.49it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  61% 313/509 [00:02<00:01, 142.94it/s]\u001b[A\n",
            "Epoch 1:  93% 2363/2542 [00:29<00:02, 80.72it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2380/2542 [00:29<00:02, 80.98it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  94% 2397/2542 [00:29<00:01, 81.22it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  95% 2414/2542 [00:29<00:01, 81.44it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2431/2542 [00:29<00:01, 81.70it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  96% 2448/2542 [00:29<00:01, 81.95it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  97% 2465/2542 [00:29<00:00, 82.20it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Validating:  85% 433/509 [00:03<00:00, 140.97it/s]\u001b[A\n",
            "Epoch 1:  98% 2482/2542 [00:30<00:00, 82.43it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  98% 2499/2542 [00:30<00:00, 82.66it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1:  99% 2516/2542 [00:30<00:00, 82.91it/s, loss=0.508, v_num=6, val_loss=0.572, val_acc=0.789]\n",
            "Epoch 1: 100% 2542/2542 [00:30<00:00, 82.82it/s, loss=0.508, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  80% 2033/2542 [00:27<00:06, 75.23it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  80% 2040/2542 [00:27<00:06, 74.90it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  81% 2057/2542 [00:27<00:06, 75.20it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2074/2542 [00:27<00:06, 75.50it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  82% 2091/2542 [00:27<00:05, 75.80it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  12% 59/509 [00:00<00:19, 23.35it/s]\u001b[A\n",
            "Epoch 2:  83% 2108/2542 [00:27<00:05, 76.09it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2125/2542 [00:27<00:05, 76.38it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  84% 2142/2542 [00:27<00:05, 76.63it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  85% 2159/2542 [00:28<00:04, 76.88it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2176/2542 [00:28<00:04, 77.16it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  86% 2193/2542 [00:28<00:04, 77.44it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  32% 161/509 [00:01<00:03, 99.62it/s]\u001b[A\n",
            "Epoch 2:  87% 2210/2542 [00:28<00:04, 77.69it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2227/2542 [00:28<00:04, 77.97it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  88% 2244/2542 [00:28<00:03, 78.25it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  89% 2261/2542 [00:28<00:03, 78.51it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2278/2542 [00:28<00:03, 78.76it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  90% 2295/2542 [00:29<00:03, 79.02it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  91% 2312/2542 [00:29<00:02, 79.26it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  55% 279/509 [00:02<00:01, 135.42it/s]\u001b[A\n",
            "Epoch 2:  92% 2329/2542 [00:29<00:02, 79.52it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  92% 2346/2542 [00:29<00:02, 79.75it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  93% 2363/2542 [00:29<00:02, 80.00it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2380/2542 [00:29<00:02, 80.25it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  94% 2397/2542 [00:29<00:01, 80.48it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  95% 2414/2542 [00:29<00:01, 80.71it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  96% 2431/2542 [00:30<00:01, 80.96it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Validating:  78% 398/509 [00:03<00:00, 137.78it/s]\u001b[A\n",
            "Epoch 2:  96% 2448/2542 [00:30<00:01, 81.20it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  97% 2465/2542 [00:30<00:00, 81.41it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2482/2542 [00:30<00:00, 81.67it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  98% 2499/2542 [00:30<00:00, 81.91it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2:  99% 2516/2542 [00:30<00:00, 82.15it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2533/2542 [00:30<00:00, 82.39it/s, loss=0.463, v_num=6, val_loss=0.528, val_acc=0.798]\n",
            "Epoch 2: 100% 2542/2542 [00:30<00:00, 82.03it/s, loss=0.463, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  80% 2033/2542 [00:27<00:06, 74.67it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  80% 2040/2542 [00:27<00:06, 74.29it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  81% 2057/2542 [00:27<00:06, 74.58it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2074/2542 [00:27<00:06, 74.91it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  82% 2091/2542 [00:27<00:05, 75.22it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  83% 2108/2542 [00:27<00:05, 75.51it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  84% 2125/2542 [00:28<00:05, 75.80it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  18% 92/509 [00:00<00:11, 35.05it/s]\u001b[A\n",
            "Epoch 3:  84% 2142/2542 [00:28<00:05, 76.10it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  85% 2159/2542 [00:28<00:05, 76.37it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2176/2542 [00:28<00:04, 76.66it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  86% 2193/2542 [00:28<00:04, 76.94it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  87% 2210/2542 [00:28<00:04, 77.22it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  36% 182/509 [00:01<00:03, 105.33it/s]\u001b[A\n",
            "Epoch 3:  90% 2278/2542 [00:29<00:03, 78.27it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  90% 2295/2542 [00:29<00:03, 78.54it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  91% 2312/2542 [00:29<00:02, 78.77it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2329/2542 [00:29<00:02, 79.05it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  92% 2346/2542 [00:29<00:02, 79.28it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  93% 2363/2542 [00:29<00:02, 79.54it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2380/2542 [00:29<00:02, 79.81it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  94% 2397/2542 [00:29<00:01, 80.08it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Validating:  72% 364/509 [00:02<00:00, 146.49it/s]\u001b[A\n",
            "Epoch 3:  95% 2414/2542 [00:30<00:01, 80.34it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2431/2542 [00:30<00:01, 80.57it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  96% 2448/2542 [00:30<00:01, 80.81it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  97% 2465/2542 [00:30<00:00, 81.05it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2482/2542 [00:30<00:00, 81.29it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  98% 2499/2542 [00:30<00:00, 81.52it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3:  99% 2516/2542 [00:30<00:00, 81.75it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2533/2542 [00:30<00:00, 82.00it/s, loss=0.437, v_num=6, val_loss=0.509, val_acc=0.805]\n",
            "Epoch 3: 100% 2542/2542 [00:31<00:00, 81.68it/s, loss=0.437, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  80% 2033/2542 [00:26<00:06, 75.63it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 4:  80% 2040/2542 [00:27<00:06, 75.26it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  81% 2057/2542 [00:27<00:06, 75.55it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  82% 2074/2542 [00:27<00:06, 75.83it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Validating:   8% 41/509 [00:00<00:29, 15.93it/s]\u001b[A\n",
            "Epoch 4:  82% 2091/2542 [00:27<00:05, 76.13it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  83% 2108/2542 [00:27<00:05, 76.40it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2125/2542 [00:27<00:05, 76.71it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  84% 2142/2542 [00:27<00:05, 76.99it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  85% 2159/2542 [00:27<00:04, 77.26it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  86% 2176/2542 [00:28<00:04, 77.52it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  28% 144/509 [00:01<00:04, 85.29it/s]\u001b[A\n",
            "Epoch 4:  86% 2193/2542 [00:28<00:04, 77.82it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  87% 2210/2542 [00:28<00:04, 78.08it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2227/2542 [00:28<00:04, 78.33it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  88% 2244/2542 [00:28<00:03, 78.59it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  89% 2261/2542 [00:28<00:03, 78.84it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2278/2542 [00:28<00:03, 79.10it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  90% 2295/2542 [00:28<00:03, 79.36it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  51% 262/509 [00:02<00:01, 135.91it/s]\u001b[A\n",
            "Epoch 4:  91% 2312/2542 [00:29<00:02, 79.63it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2329/2542 [00:29<00:02, 79.88it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  92% 2346/2542 [00:29<00:02, 80.13it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  93% 2363/2542 [00:29<00:02, 80.38it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2380/2542 [00:29<00:02, 80.62it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  94% 2397/2542 [00:29<00:01, 80.87it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  95% 2414/2542 [00:29<00:01, 81.13it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Validating:  75% 382/509 [00:02<00:00, 141.73it/s]\u001b[A\n",
            "Epoch 4:  96% 2431/2542 [00:29<00:01, 81.36it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  96% 2448/2542 [00:29<00:01, 81.62it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  97% 2465/2542 [00:30<00:00, 81.86it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2482/2542 [00:30<00:00, 82.10it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  98% 2499/2542 [00:30<00:00, 82.31it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4:  99% 2516/2542 [00:30<00:00, 82.55it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2533/2542 [00:30<00:00, 82.78it/s, loss=0.408, v_num=6, val_loss=0.498, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 82.71it/s, loss=0.408, v_num=6, val_loss=0.505, val_acc=0.807]\n",
            "Epoch 4: 100% 2542/2542 [00:30<00:00, 82.25it/s, loss=0.408, v_num=6, val_loss=0.505, val_acc=0.807]\n",
            "Testing: 100% 422/422 [00:03<00:00, 134.27it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8061, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}